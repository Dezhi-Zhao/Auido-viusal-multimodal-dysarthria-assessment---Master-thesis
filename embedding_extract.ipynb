{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae025bfd-683b-4b3f-9943-0c4f239561f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import json\n",
    "import av\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.io import read_video\n",
    "import torchvision.models.video as video_models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torchvision.transforms import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a6630c-f41b-45e7-8d2f-8303477f2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "# Normalization constants\n",
    "AUDIO_MEAN = [0.485, 0.456, 0.406]\n",
    "AUDIO_STD = [0.229, 0.224, 0.225]\n",
    "VIDEO_MEAN = [0.43216, 0.394666, 0.37645]\n",
    "VIDEO_STD = [0.22803, 0.22145, 0.216989]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44478403-9bac-42cb-b238-9e34dcabdb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Line 1919] Skipping malformed JSON: Extra data: line 1 column 120 (char 119)\n",
      "Processed 200 items...\n",
      "Processed 400 items...\n",
      "Processed 600 items...\n",
      "Processed 800 items...\n",
      "Processed 1000 items...\n",
      "Processed 1200 items...\n",
      "Processed 1400 items...\n",
      "Processed 1600 items...\n",
      "Processed 1800 items...\n",
      "Processed 2000 items...\n",
      "Processed 2200 items...\n",
      "Processed 2400 items...\n",
      "Processed 2600 items...\n",
      "Processed 2800 items...\n",
      "Processed 3000 items...\n",
      "Processed 3200 items...\n",
      "Processed 3400 items...\n",
      "Processed 3600 items...\n",
      "Processed 3800 items...\n",
      "Processed 4000 items...\n",
      "Processed 4200 items...\n",
      "Processed 4400 items...\n",
      "Processed 4600 items...\n",
      "Processed 4800 items...\n",
      "Processed 5000 items...\n",
      "Processed 5200 items...\n",
      "Processed 5400 items...\n",
      "Processed 5600 items...\n",
      "Processed 5800 items...\n",
      "Processed 6000 items...\n",
      "Processed 6200 items...\n",
      "Processed 6400 items...\n",
      "Processed 6600 items...\n",
      "Processed 6800 items...\n",
      "Processed 7000 items...\n",
      "Processed 7200 items...\n",
      "Processed 7400 items...\n",
      "Processed 7600 items...\n",
      "Processed 7800 items...\n",
      "Processed 8000 items...\n",
      "Processed 8200 items...\n",
      "Processed 8400 items...\n",
      "Processed 8600 items...\n",
      "Processed 8800 items...\n",
      "Processed 9000 items...\n",
      "Processed 9200 items...\n",
      "Processed 9400 items...\n",
      "Processed 9600 items...\n",
      "Processed 9800 items...\n",
      "Processed 10000 items...\n",
      "Processed 10200 items...\n",
      "Processed 10400 items...\n",
      "Processed 10600 items...\n",
      "Processed 10800 items...\n",
      "Processed 11000 items...\n",
      "Processed 11200 items...\n",
      "Processed 11400 items...\n",
      "Processed 11600 items...\n",
      "Processed 11800 items...\n",
      "Processed 12000 items...\n",
      "Processed 12200 items...\n",
      "Processed 12400 items...\n",
      "Processed 12600 items...\n",
      "Processed 12800 items...\n",
      "Processed 13000 items...\n",
      "Processed 13200 items...\n",
      "Processed 13400 items...\n",
      "Processed 13600 items...\n",
      "Processed 13800 items...\n",
      "Processed 14000 items...\n",
      "Processed 14200 items...\n",
      "Processed 14400 items...\n",
      "Processed 14600 items...\n",
      "Processed 14800 items...\n",
      "Processed 15000 items...\n",
      "Processed 15200 items...\n",
      "Processed 15400 items...\n",
      "Processed 15600 items...\n",
      "Processed 15800 items...\n",
      "Processed 16000 items...\n",
      "Processed 16200 items...\n",
      "Processed 16400 items...\n",
      "Processed 16600 items...\n",
      "Processed 16800 items...\n",
      "Processed 17000 items...\n",
      "Processed 17200 items...\n",
      "Processed 17400 items...\n",
      "Processed 17600 items...\n",
      "Processed 17800 items...\n",
      "Processed 18000 items...\n",
      "Processed 18200 items...\n",
      "Processed 18400 items...\n",
      "Processed 18600 items...\n",
      "Processed 18800 items...\n",
      "Processed 19000 items...\n",
      "Processed 19200 items...\n",
      "Processed 19400 items...\n",
      "Processed 19600 items...\n",
      "Processed 19800 items...\n",
      "Processed 20000 items...\n",
      "Processed 20200 items...\n",
      "Processed 20400 items...\n",
      "Processed 20600 items...\n",
      "Processed 20800 items...\n",
      "Processed 21000 items...\n",
      "Processed 21200 items...\n",
      "Processed 21400 items...\n",
      "Processed 21600 items...\n",
      "Processed 21800 items...\n",
      "Processed 22000 items...\n",
      "Processed 22200 items...\n",
      "Processed 22400 items...\n",
      "Processed 22600 items...\n",
      "Processed 22800 items...\n",
      "Processed 23000 items...\n",
      "Processed 23200 items...\n",
      "Processed 23400 items...\n",
      "Processed 23600 items...\n",
      "Processed 23800 items...\n",
      "Processed 24000 items...\n",
      "Processed 24200 items...\n",
      "Processed 24400 items...\n",
      "Processed 24600 items...\n",
      "Processed 24800 items...\n",
      "Processed 25000 items...\n",
      "Processed 25200 items...\n",
      "Processed 25400 items...\n",
      "Processed 25600 items...\n",
      "Processed 25800 items...\n",
      "Processed 26000 items...\n",
      "Processed 26200 items...\n",
      "Processed 26400 items...\n",
      "Processed 26600 items...\n",
      "Processed 26800 items...\n",
      "Processed 27000 items...\n",
      "Processed 27200 items...\n",
      "Processed 27400 items...\n",
      "Processed 27600 items...\n",
      "Processed 27800 items...\n",
      "Processed 28000 items...\n",
      "Processed 28200 items...\n",
      "Processed 28400 items...\n",
      "Processed 28600 items...\n",
      "Processed 28800 items...\n",
      "Processed 29000 items...\n",
      "Processed 29200 items...\n",
      "Processed 29400 items...\n",
      "Processed 29600 items...\n",
      "Processed 29800 items...\n",
      "Processed 30000 items...\n",
      "Processed 30200 items...\n",
      "Processed 30400 items...\n",
      "Processed 30600 items...\n",
      "Processed 30800 items...\n",
      "Processed 31000 items...\n",
      "Processed 31200 items...\n",
      "Processed 31400 items...\n",
      "Processed 31600 items...\n",
      "Processed 31800 items...\n",
      "Processed 32000 items...\n",
      "Processed 32200 items...\n",
      "Processed 32400 items...\n",
      "Processed 32600 items...\n",
      "Processed 32800 items...\n",
      "Processed 33000 items...\n",
      "Processed 33200 items...\n",
      "Processed 33400 items...\n",
      "Processed 33600 items...\n",
      "Processed 33800 items...\n",
      "Processed 34000 items...\n",
      "Processed 34200 items...\n",
      "Processed 34400 items...\n",
      "Processed 34600 items...\n",
      "Processed 34800 items...\n",
      "Processed 35000 items...\n",
      "Processed 35200 items...\n",
      "Processed 35400 items...\n",
      "Processed 35600 items...\n",
      "Processed 35800 items...\n",
      "Processed 36000 items...\n",
      "Processed 36200 items...\n",
      "Processed 36400 items...\n",
      "Processed 36600 items...\n",
      "Processed 36800 items...\n",
      "Processed 37000 items...\n",
      "Processed 37200 items...\n",
      "Processed 37400 items...\n",
      "Processed 37600 items...\n",
      "Processed 37800 items...\n",
      "Processed 38000 items...\n",
      "Processed 38200 items...\n",
      "Processed 38400 items...\n",
      "Processed 38600 items...\n",
      "Processed 38800 items...\n",
      "Processed 39000 items...\n",
      "Processed 39200 items...\n",
      "Processed 39400 items...\n",
      "Processed 39600 items...\n",
      "Processed 39800 items...\n",
      "Processed 40000 items...\n",
      "Processed 40200 items...\n",
      "Processed 40400 items...\n",
      "Processed 40600 items...\n",
      "Processed 40800 items...\n",
      "Processed 41000 items...\n",
      "Processed 41200 items...\n",
      "Processed 41400 items...\n",
      "Processed 41600 items...\n",
      "Processed 41800 items...\n",
      "Processed 42000 items...\n",
      "Processed 42200 items...\n",
      "Processed 42400 items...\n",
      "Processed 42600 items...\n",
      "Processed 42800 items...\n",
      "Processed 43000 items...\n",
      "Processed 43200 items...\n",
      "Processed 43400 items...\n",
      "Processed 43600 items...\n",
      "Processed 43800 items...\n",
      "Processed 44000 items...\n",
      "Processed 44200 items...\n",
      "Processed 44400 items...\n",
      "Processed 44600 items...\n",
      "Processed 44800 items...\n",
      "Processed 45000 items...\n",
      "Processed 45200 items...\n",
      "Processed 45400 items...\n",
      "Processed 45600 items...\n",
      "Processed 45800 items...\n",
      "Processed 46000 items...\n",
      "Processed 46200 items...\n",
      "Processed 46400 items...\n",
      "Processed 46600 items...\n",
      "Processed 46800 items...\n",
      "Processed 47000 items...\n",
      "Processed 47200 items...\n",
      "Processed 47400 items...\n",
      "Processed 47600 items...\n",
      "Processed 47800 items...\n",
      "Processed 48000 items...\n",
      "Processed 48200 items...\n",
      "Processed 48400 items...\n",
      "Processed 48600 items...\n",
      "Processed 48800 items...\n",
      "Processed 49000 items...\n",
      "Processed 49200 items...\n",
      "Processed 49400 items...\n",
      "Processed 49600 items...\n",
      "Processed 49800 items...\n",
      "Processed 50000 items...\n",
      "Processed 50200 items...\n",
      "Processed 50400 items...\n",
      "Processed 50600 items...\n",
      "Processed 50800 items...\n",
      "Processed 51000 items...\n",
      "Processed 51200 items...\n",
      "Processed 51400 items...\n",
      "Processed 51600 items...\n",
      "Processed 51800 items...\n",
      "Processed 52000 items...\n",
      "Processed 52200 items...\n",
      "Processed 52400 items...\n",
      "Processed 52600 items...\n",
      "Processed 52800 items...\n",
      "Processed 53000 items...\n",
      "Processed 53200 items...\n",
      "Processed 53400 items...\n",
      "Processed 53600 items...\n",
      "Processed 53800 items...\n",
      "Processed 54000 items...\n",
      "Processed 54200 items...\n",
      "Processed 54400 items...\n",
      "Processed 54600 items...\n",
      "Processed 54800 items...\n",
      "Processed 55000 items...\n",
      "Processed 55200 items...\n",
      "Processed 55400 items...\n",
      "Processed 55600 items...\n",
      "Processed 55800 items...\n",
      "Processed 56000 items...\n",
      "Processed 56200 items...\n",
      "Processed 56400 items...\n",
      "Processed 56600 items...\n",
      "Processed 56800 items...\n",
      "Processed 57000 items...\n",
      "Processed 57200 items...\n",
      "Processed 57400 items...\n",
      "Processed 57600 items...\n",
      "Processed 57800 items...\n",
      "Processed 58000 items...\n",
      "Processed 58200 items...\n",
      "Processed 58400 items...\n",
      "Processed 58600 items...\n",
      "Processed 58800 items...\n",
      "Processed 59000 items...\n",
      "Processed 59200 items...\n",
      "Processed 59400 items...\n",
      "Processed 59600 items...\n",
      "Processed 59800 items...\n",
      "Processed 60000 items...\n",
      "Processed 60200 items...\n",
      "Processed 60400 items...\n",
      "Finished. Total processed: 60476\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "class AudioVideoDataset(Dataset):\n",
    "    def __init__(self, data_list, indices, spec_dir='spectrograms', fixed_samples=16000, fps=25):\n",
    "        self.data = [data_list[i] for i in indices]\n",
    "        self.spec_dir = spec_dir\n",
    "        self.fixed_samples = fixed_samples\n",
    "        self.fps = fps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_path, video_path, label, key = self.data[idx]\n",
    "        spec_path = os.path.join(self.spec_dir, f'spec_{key}.npy')\n",
    "        spec = torch.from_numpy(np.load(spec_path)).float()\n",
    "        _, video = load_aligned_pair(wav_path, video_path, self.fixed_samples, self.fps)\n",
    "        return spec, video, label, key\n",
    "\n",
    "# Video loading\n",
    "def load_aligned_pair(wav_path, video_path, fixed_samples=16000, fps=25):\n",
    "    audio_duration = fixed_samples / 16000\n",
    "    video_frames = int(audio_duration * fps)\n",
    "    video, _, _ = read_video(video_path, pts_unit='sec')\n",
    "    video = video.float() / 255.0\n",
    "    if video.shape[0] > video_frames:\n",
    "        video = video[:video_frames]\n",
    "    elif video.shape[0] < video_frames:\n",
    "        video = F.pad(video, (0, 0, 0, 0, 0, video_frames - video.shape[0]))\n",
    "    video = video.permute(0, 3, 1, 2)\n",
    "    video = F.interpolate(video, size=(112, 112), mode='bilinear', align_corners=False)\n",
    "    video = video.permute(1, 0, 2, 3)\n",
    "    return None, video\n",
    "\n",
    "# Collate\n",
    "def collate_fn(batch):\n",
    "    specs, videos, labels, keys = zip(*batch)\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    specs = torch.stack(specs).unsqueeze(1).to(device)\n",
    "    specs = F.interpolate(specs, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "    specs = specs.repeat(1, 3, 1, 1)\n",
    "    specs = (specs - torch.tensor(AUDIO_MEAN, device=device).view(1, 3, 1, 1)) / torch.tensor(AUDIO_STD, device=device).view(1, 3, 1, 1)\n",
    "    videos = torch.stack(videos).to(device)\n",
    "    videos = (videos - torch.tensor(VIDEO_MEAN, device=device).view(1, 3, 1, 1, 1)) / torch.tensor(VIDEO_STD, device=device).view(1, 3, 1, 1, 1)\n",
    "    labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "    return specs, videos, labels, keys\n",
    "\n",
    "# Audio model\n",
    "class AudioResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_features, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "# Video model\n",
    "class VideoModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.resnet3d = r3d_18(weights=R3D_18_Weights.KINETICS400_V1)\n",
    "        in_features = self.resnet3d.fc.in_features\n",
    "        self.resnet3d.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_features, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet3d(x)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        x = self.resnet3d.stem(x)\n",
    "        x = self.resnet3d.layer1(x)\n",
    "        x = self.resnet3d.layer2(x)\n",
    "        x = self.resnet3d.layer3(x)\n",
    "        x = self.resnet3d.layer4(x)\n",
    "        x = self.resnet3d.avgpool(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "# Save batch\n",
    "def save_batch(audio_embeds, video_embeds, metadata, batch_num, output_dir):\n",
    "    batch_dir = os.path.join(output_dir, f'batch_{batch_num}')\n",
    "    os.makedirs(batch_dir, exist_ok=True)\n",
    "    for i, (ae, ve, meta) in enumerate(zip(audio_embeds, video_embeds, metadata)):\n",
    "        key = meta['key']\n",
    "        np.save(os.path.join(batch_dir, f'audio_embed_{key}.npy'), ae)\n",
    "        np.save(os.path.join(batch_dir, f'video_embed_{key}.npy'), ve)\n",
    "        with open(os.path.join(batch_dir, f'meta_{key}.json'), 'w') as f:\n",
    "            json.dump(meta, f)\n",
    "\n",
    "# Main extraction function\n",
    "def extract_finetuned_embeddings(audio_model, video_model, file_path='data_copy.list', output_dir='features_finetuned', batch_size=16, device='cuda:0'):\n",
    "    audio_model.eval()\n",
    "    video_model.eval()\n",
    "\n",
    "    data_list = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"[Line {line_num}] Skipping malformed JSON: {e}\")\n",
    "                continue\n",
    "            key = entry['key']\n",
    "            wav_path = os.path.join('audio', os.path.basename(entry['wav_path']))\n",
    "            video_path = os.path.join('video', os.path.splitext(os.path.basename(entry['wav_path']))[0] + '.avi')\n",
    "            label = int(entry['label'])\n",
    "            spec_path = os.path.join('spectrograms', f'spec_{key}.npy')\n",
    "            if os.path.exists(wav_path) and os.path.exists(video_path) and os.path.exists(spec_path):\n",
    "                data_list.append((wav_path, video_path, label, key))\n",
    "\n",
    "    indices = list(range(len(data_list)))\n",
    "    dataset = AudioVideoDataset(data_list, indices)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False, collate_fn=collate_fn)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch_num = 0\n",
    "    batch_audio_embeds, batch_video_embeds, batch_metadata = [], [], []\n",
    "    processed = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for specs, videos, labels, keys in loader:\n",
    "            ae = audio_model.get_embedding(specs)\n",
    "            ve = video_model.get_embedding(videos)\n",
    "            for i in range(specs.size(0)):\n",
    "                batch_audio_embeds.append(ae[i].cpu().numpy())\n",
    "                batch_video_embeds.append(ve[i].cpu().numpy())\n",
    "                batch_metadata.append({\n",
    "                    'key': keys[i],\n",
    "                    'label': labels[i].item(),\n",
    "                    'wav_path': data_list[batch_num * batch_size + i][0],\n",
    "                    'video_path': data_list[batch_num * batch_size + i][1]\n",
    "                })\n",
    "                processed += 1\n",
    "                if processed % 200 == 0:\n",
    "                    print(f\"Processed {processed} items...\")\n",
    "                if len(batch_audio_embeds) >= batch_size:\n",
    "                    save_batch(batch_audio_embeds, batch_video_embeds, batch_metadata, batch_num, output_dir)\n",
    "                    batch_audio_embeds, batch_video_embeds, batch_metadata = [], [], []\n",
    "                    batch_num += 1\n",
    "\n",
    "    if batch_audio_embeds:\n",
    "        save_batch(batch_audio_embeds, batch_video_embeds, batch_metadata, batch_num, output_dir)\n",
    "\n",
    "    print(f\"Finished. Total processed: {processed}\")\n",
    "\n",
    "# Entry point\n",
    "def main():\n",
    "    set_seed()\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    audio_model = AudioResNet().to(device)\n",
    "    video_model = VideoModel().to(device)\n",
    "    audio_model.load_state_dict(torch.load('audio_finetuned.pth', map_location=device))\n",
    "    video_model.load_state_dict(torch.load('video_finetuned.pth', map_location=device))\n",
    "    extract_finetuned_embeddings(audio_model, video_model, file_path='data_copy.list', output_dir='features_finetuned', batch_size=16, device=device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c3aa5-6e6c-401d-84e8-8c302970139f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb422640-d2e0-46fe-a7b6-19825b4fad9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

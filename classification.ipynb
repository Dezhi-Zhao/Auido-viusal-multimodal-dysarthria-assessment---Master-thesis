{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da807a65-427d-4a5c-a3b9-3351a3bab731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting av\n",
      "  Downloading av-14.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Downloading av-14.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: av\n",
      "Successfully installed av-14.4.0\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (80.1.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch)\n",
      "  Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (865.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.0/865.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m138.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m151.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m141.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m211.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m142.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m249.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m156.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m141.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m140.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m140.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m139.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m157.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m150.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m236.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [torch]m20/21\u001b[0m [torch]-cusolver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.18.0 fsspec-2025.5.0 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /opt/conda/lib/python3.12/site-packages (from librosa) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from librosa)\n",
      "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting joblib>=1.0 (from librosa)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.12/site-packages (from librosa) (5.2.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /opt/conda/lib/python3.12/site-packages (from librosa) (4.13.2)\n",
      "Collecting lazy_loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.12/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m140.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m160.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, soxr, scipy, msgpack, llvmlite, lazy_loader, joblib, audioread, soundfile, scikit-learn, pooch, numba, librosa\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/13\u001b[0m [librosa]1/13\u001b[0m [numba]-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed audioread-3.0.1 joblib-1.5.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 msgpack-1.1.0 numba-0.61.2 pooch-1.8.2 scikit-learn-1.6.1 scipy-1.15.3 soundfile-0.13.1 soxr-0.5.0.post1 threadpoolctl-3.6.0\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: torch==2.7.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (80.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (2025.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
      "Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.22.0\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torch==2.7.0 in /opt/conda/lib/python3.12/site-packages (from torchaudio) (2.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (80.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (2025.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.0->torchaudio) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.7.0->torchaudio) (3.0.2)\n",
      "Downloading torchaudio-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.7.0\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.12/site-packages (from h5py) (2.2.5)\n",
      "Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h5py\n",
      "Successfully installed h5py-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install av\n",
    "!pip install torch\n",
    "!pip install librosa\n",
    "!pip install os\n",
    "!pip install json\n",
    "!pip install torchvision\n",
    "!pip install torchaudio\n",
    "!pip install h5py\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc70e33d-5040-4ae6-ba12-a4bb2029a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import av\n",
    "import h5py\n",
    "#import seaborn as sns\n",
    "import sklearn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b85990-5f4d-4c81-83f4-cb0fd05218da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from torchvision.io import read_video\n",
    "from torchvision.models.video import r3d_18\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa76e627-6303-4e50-9ccf-849dfa14891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA H100 80GB HBM3\n",
      "Number of GPUs: 1\n",
      "GPU Memory Allocated: 0.00 MB\n",
      "GPU Memory Reserved: 0.00 MB\n",
      "Tensor successfully created on GPU: tensor([[0.7457, 0.2001, 0.8995],\n",
      "        [0.8750, 0.8683, 0.1055],\n",
      "        [0.4326, 0.8927, 0.2116]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(f\"CUDA Available: {gpu_available}\")\n",
    "\n",
    "if gpu_available:\n",
    "    # Get the GPU name\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Get the number of GPUs\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # Get the current GPU memory usage\n",
    "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "    print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Test a simple tensor operation on GPU\n",
    "    x = torch.rand(3, 3).cuda()\n",
    "    print(\"Tensor successfully created on GPU:\", x)\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc8d7ad-2605-48f0-ad33-7e13d8be22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895352e8-a303-4bf7-bc12-c561165289c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing notebook: classification_finetuned.ipynb\n"
     ]
    }
   ],
   "source": [
    "!jupyter trust classification_finetuned.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2485655-14a8-4f5d-9108-b5a2a7631ff1",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df53af5b-2c8f-49bb-a7da-c9c1c2caecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: 41734, Val indices: 9465, Test indices: 9277\n",
      "JSON error at line 1919: Extra data: line 1 column 120 (char 119), line content: {\"key\": \"S_M_00051_G2_task1_4_S00004\", \"wav_path\": \"data/S_M_00051_G2_task1_4_S00004.wav\", \"label\": 1, \"Frenchay\": 114}4{\"key\": \"S_M_00020_G4_task1_5_S00007\", \"wav_path\": \"data/S_M_00020_G4_task1_5_S00007.wav\", \"label\": 1, \"Frenchay\": 92}, skipping.\n",
      "Loaded 60476 valid clips, skipped 6712 entries from data_copy.list.\n",
      "Loading training embeddings...\n",
      "Loaded 1000 embeddings so far.\n",
      "Loaded 2000 embeddings so far.\n",
      "Loaded 3000 embeddings so far.\n",
      "Loaded 4000 embeddings so far.\n",
      "Loaded 5000 embeddings so far.\n",
      "Loaded 6000 embeddings so far.\n",
      "Loaded 7000 embeddings so far.\n",
      "Loaded 8000 embeddings so far.\n",
      "Loaded 9000 embeddings so far.\n",
      "Loaded 10000 embeddings so far.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Load embeddings into memory\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading training embeddings...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m X_train_audio, X_train_video, y_train, train_keys, mean_std = \u001b[43mload_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfeatures_2w_finetuned\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading validation embeddings...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    125\u001b[39m X_val_audio, X_val_video, y_val, val_keys, _ = load_embeddings(val_indices, data_list, embeddings_dir=\u001b[33m'\u001b[39m\u001b[33mfeatures_2w_finetuned\u001b[39m\u001b[33m'\u001b[39m, batch_size=\u001b[32m16\u001b[39m, normalize=\u001b[38;5;28;01mTrue\u001b[39;00m, mean_std=mean_std)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mload_embeddings\u001b[39m\u001b[34m(indices, data_list, embeddings_dir, batch_size, normalize, mean_std)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     73\u001b[39m X_audio.append(np.load(audio_embed_path))\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m X_video.append(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_embed_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     75\u001b[39m y.append(label)\n\u001b[32m     76\u001b[39m keys.append(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:458\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    456\u001b[39m _ZIP_SUFFIX = \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPK\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# empty zip files start with this\u001b[39;00m\n\u001b[32m    457\u001b[39m N = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX)\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m magic = \u001b[43mfid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m magic:\n\u001b[32m    460\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo data left in file\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# z-score normalization \n",
    "# Load data list from JSON lines\n",
    "def load_data_list(file_path='data_copy.list'):\n",
    "    data_list = []\n",
    "    all_keys =[]\n",
    "    skipped = 0\n",
    "    loaded = 0\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                entry = json.loads(line.strip())\n",
    "                if 'key' not in entry or 'wav_path' not in entry or 'label' not in entry:\n",
    "                    print(f\"Key error at line {line_num}: Missing 'key', 'wav_path', or 'label', line content: {line.strip()}\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                key = entry['key']\n",
    "                wav_path = os.path.join('audio', os.path.basename(entry['wav_path']))\n",
    "                video_path = os.path.join('video', os.path.splitext(os.path.basename(entry['wav_path']))[0] + '.avi')\n",
    "                label = int(entry['label'])\n",
    "                if label not in [0, 1, 2, 3]:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                spec_path = os.path.join('spectrograms', f'spec_{key}.npy')\n",
    "                if not os.path.exists(wav_path) or not os.path.exists(video_path) or not os.path.exists(spec_path):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                data_list.append((wav_path, video_path, label, key))\n",
    "                loaded += 1\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON error at line {line_num}: {e}, line content: {line.strip()}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            except KeyError as e:\n",
    "                print(f\"Key error at line {line_num}: Missing {e}, line content: {line.strip()}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            all_keys.append(key)\n",
    "    print(f\"Loaded {loaded} valid clips, skipped {skipped} entries from {file_path}.\")\n",
    "    return data_list, all_keys\n",
    "\n",
    "# Z-score normalization\n",
    "def zscore_normalize(X, mean=None, std=None):\n",
    "    if mean is None:\n",
    "        mean = X.mean(axis=0)\n",
    "    if std is None:\n",
    "        std = X.std(axis=0)\n",
    "    std[std == 0] = 1.0\n",
    "    return (X - mean) / std, mean, std\n",
    "\n",
    "# Load saved audio/video embeddings\n",
    "\n",
    "def load_embeddings(indices, data_list, embeddings_dir='features_2w_finetuned', batch_size=16, normalize=True, mean_std=None):\n",
    "    X_audio, X_video, y, keys = [], [], [], []\n",
    "    skipped = 0\n",
    "    loaded = 0\n",
    "    for i in indices:\n",
    "        if i >= len(data_list):\n",
    "            print(f\"Index {i} exceeds data_list length {len(data_list)}, skipping.\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "        try:\n",
    "            key = data_list[i][3]\n",
    "            label = data_list[i][2]\n",
    "            batch_num = i // batch_size\n",
    "            audio_embed_path = os.path.join(embeddings_dir, f'batch_{batch_num}', f'audio_embed_{key}.npy')\n",
    "            video_embed_path = os.path.join(embeddings_dir, f'batch_{batch_num}', f'video_embed_{key}.npy')\n",
    "            if not os.path.exists(audio_embed_path) or not os.path.exists(video_embed_path):\n",
    "                print(f\"Missing embedding for key {key}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            X_audio.append(np.load(audio_embed_path))\n",
    "            X_video.append(np.load(video_embed_path))\n",
    "            y.append(label)\n",
    "            keys.append(key)\n",
    "            loaded += 1\n",
    "            if loaded % 1000 == 0:\n",
    "                print(f\"Loaded {loaded} embeddings so far.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embedding for index {i}, key {data_list[i][3]}: {e}, skipping.\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "    print(f\"Loaded {loaded} embeddings, skipped {skipped} entries.\")\n",
    "\n",
    "    X_audio = np.array(X_audio)\n",
    "    X_video = np.array(X_video)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if normalize:\n",
    "        if mean_std is None:\n",
    "            X_audio, audio_mean, audio_std = zscore_normalize(X_audio)\n",
    "            X_video, video_mean, video_std = zscore_normalize(X_video)\n",
    "            mean_std = (audio_mean, audio_std, video_mean, video_std)\n",
    "        else:\n",
    "            audio_mean, audio_std, video_mean, video_std = mean_std\n",
    "            X_audio, _, _ = zscore_normalize(X_audio, audio_mean, audio_std)\n",
    "            X_video, _, _ = zscore_normalize(X_video, video_mean, video_std)\n",
    "\n",
    "    return X_audio, X_video, y, keys, mean_std\n",
    "\n",
    "# Load train/val/test indices\n",
    "try:\n",
    "    train_indices = np.load('train_indices.npy')\n",
    "    val_indices = np.load('val_indices.npy')\n",
    "    test_indices = np.load('test_indices.npy')\n",
    "    print(f\"Train indices: {len(train_indices)}, Val indices: {len(val_indices)}, Test indices: {len(test_indices)}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Ensure train_indices.npy, val_indices.npy, test_indices.npy exist.\")\n",
    "    raise\n",
    "\n",
    "# Load full data list\n",
    "data_list, all_keys = load_data_list('data_copy.list')\n",
    "\n",
    "# Sanity check on indices\n",
    "max_index = len(data_list) - 1\n",
    "if max(train_indices) > max_index or max(val_indices) > max_index or max(test_indices) > max_index:\n",
    "    print(f\"Error: Indices exceed data_list length ({max_index}). Re-run split_dataset.py with data_copy.list.\")\n",
    "    raise ValueError(\"Invalid indices.\")\n",
    "\n",
    "# Load embeddings into memory\n",
    "print(\"Loading training embeddings...\")\n",
    "X_train_audio, X_train_video, y_train, train_keys, mean_std = load_embeddings(train_indices, data_list, embeddings_dir='features_2w_finetuned', batch_size=16, normalize=True)\n",
    "print(\"Loading validation embeddings...\")\n",
    "X_val_audio, X_val_video, y_val, val_keys, _ = load_embeddings(val_indices, data_list, embeddings_dir='features_2w_finetuned', batch_size=16, normalize=True, mean_std=mean_std)\n",
    "print(\"Loading test embeddings...\")\n",
    "X_test_audio, X_test_video, y_test, test_keys, _ = load_embeddings(test_indices, data_list, embeddings_dir='features_2w_finetuned', batch_size=16, normalize=True, mean_std=mean_std)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_audio, dtype=torch.float32),\n",
    "                               torch.tensor(X_train_video, dtype=torch.float32),\n",
    "                               torch.tensor(y_train, dtype=torch.long))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val_audio, dtype=torch.float32),\n",
    "                             torch.tensor(X_val_video, dtype=torch.float32),\n",
    "                             torch.tensor(y_val, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test_audio, dtype=torch.float32),\n",
    "                              torch.tensor(X_test_video, dtype=torch.float32),\n",
    "                              torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46bb39-8b25-4a7a-a80c-61f0f2bb978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: 41734, Val indices: 9465, Test indices: 9277\n",
      "JSON error at line 1919: Extra data: line 1 column 120 (char 119), line content: {\"key\": \"S_M_00051_G2_task1_4_S00004\", \"wav_path\": \"data/S_M_00051_G2_task1_4_S00004.wav\", \"label\": 1, \"Frenchay\": 114}4{\"key\": \"S_M_00020_G4_task1_5_S00007\", \"wav_path\": \"data/S_M_00020_G4_task1_5_S00007.wav\", \"label\": 1, \"Frenchay\": 92}, skipping.\n",
      "Loaded 60476 valid clips, skipped 6712 entries from data_copy.list.\n",
      "Loading training embeddings...\n",
      "Loaded 5000 embeddings so far.\n",
      "Loaded 10000 embeddings so far.\n",
      "Loaded 15000 embeddings so far.\n",
      "Loaded 20000 embeddings so far.\n"
     ]
    }
   ],
   "source": [
    "# l2 norm\n",
    "# Load data list from JSON lines\n",
    "def load_data_list(file_path='data_copy.list'):\n",
    "    data_list = []\n",
    "    all_keys =[]\n",
    "    skipped = 0\n",
    "    loaded = 0\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                entry = json.loads(line.strip())\n",
    "                if 'key' not in entry or 'wav_path' not in entry or 'label' not in entry:\n",
    "                    print(f\"Key error at line {line_num}: Missing 'key', 'wav_path', or 'label', line content: {line.strip()}\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                key = entry['key']\n",
    "                wav_path = os.path.join('audio', os.path.basename(entry['wav_path']))\n",
    "                video_path = os.path.join('video', os.path.splitext(os.path.basename(entry['wav_path']))[0] + '.avi')\n",
    "                label = int(entry['label'])\n",
    "                if label not in [0, 1, 2, 3]:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                spec_path = os.path.join('spectrograms', f'spec_{key}.npy')\n",
    "                if not os.path.exists(wav_path) or not os.path.exists(video_path) or not os.path.exists(spec_path):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                data_list.append((wav_path, video_path, label, key))\n",
    "                loaded += 1\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON error at line {line_num}: {e}, line content: {line.strip()}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            except KeyError as e:\n",
    "                print(f\"Key error at line {line_num}: Missing {e}, line content: {line.strip()}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            all_keys.append(key)\n",
    "    print(f\"Loaded {loaded} valid clips, skipped {skipped} entries from {file_path}.\")\n",
    "    return data_list, all_keys\n",
    "\n",
    "# Normalize embeddings (L2)\n",
    "def l2_normalize(X):\n",
    "    return X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "# Load saved audio/video embeddings\n",
    "\n",
    "def load_embeddings(indices, data_list, embeddings_dir='features_finetuned', batch_size=16):\n",
    "    X_audio, X_video, y = [], [], []\n",
    "    skipped = 0\n",
    "    loaded = 0\n",
    "    for i in indices:\n",
    "        if i >= len(data_list):\n",
    "            print(f\"Index {i} exceeds data_list length {len(data_list)}, skipping.\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "        try:\n",
    "            key = data_list[i][3]\n",
    "            label = data_list[i][2]\n",
    "            batch_num = i // batch_size\n",
    "            audio_embed_path = os.path.join(embeddings_dir, f'batch_{batch_num}', f'audio_embed_{key}.npy')\n",
    "            video_embed_path = os.path.join(embeddings_dir, f'batch_{batch_num}', f'video_embed_{key}.npy')\n",
    "            if not os.path.exists(audio_embed_path) or not os.path.exists(video_embed_path):\n",
    "                print(f\"Missing embedding for key {key}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            X_audio.append(np.load(audio_embed_path))\n",
    "            X_video.append(np.load(video_embed_path))\n",
    "            y.append(label)\n",
    "            loaded += 1\n",
    "            if loaded % 5000 == 0:\n",
    "                print(f\"Loaded {loaded} embeddings so far.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embedding for index {i}, key {data_list[i][3]}: {e}, skipping.\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "    print(f\"Loaded {loaded} embeddings, skipped {skipped} entries.\")\n",
    "    # Normalize before returning\n",
    "    return l2_normalize(np.array(X_audio)), l2_normalize(np.array(X_video)), np.array(y)\n",
    "\n",
    "# Load train/val/test indices\n",
    "try:\n",
    "    train_indices = np.load('train_indices.npy')\n",
    "    val_indices = np.load('val_indices.npy')\n",
    "    test_indices = np.load('test_indices.npy')\n",
    "    print(f\"Train indices: {len(train_indices)}, Val indices: {len(val_indices)}, Test indices: {len(test_indices)}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Ensure train_indices.npy, val_indices.npy, test_indices.npy exist.\")\n",
    "    raise\n",
    "\n",
    "# Load full data list\n",
    "data_list, all_keys = load_data_list('data_copy.list')\n",
    "\n",
    "# Sanity check on indices\n",
    "max_index = len(data_list) - 1\n",
    "if max(train_indices) > max_index or max(val_indices) > max_index or max(test_indices) > max_index:\n",
    "    print(f\"Error: Indices exceed data_list length ({max_index}). Re-run split_dataset.py with data_copy.list.\")\n",
    "    raise ValueError(\"Invalid indices.\")\n",
    "\n",
    "# Load embeddings into memory\n",
    "print(\"Loading training embeddings...\")\n",
    "X_train_audio, X_train_video, y_train = load_embeddings(train_indices, data_list, embeddings_dir='features_finetuned', batch_size=16)\n",
    "print(\"Loading validation embeddings...\")\n",
    "X_val_audio, X_val_video, y_val = load_embeddings(val_indices, data_list, embeddings_dir='features_finetuned', batch_size=16)\n",
    "print(\"Loading test embeddings...\")\n",
    "X_test_audio, X_test_video, y_test = load_embeddings(test_indices, data_list, embeddings_dir='features_finetuned', batch_size=16)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_audio, dtype=torch.float32),\n",
    "                               torch.tensor(X_train_video, dtype=torch.float32),\n",
    "                               torch.tensor(y_train, dtype=torch.long))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val_audio, dtype=torch.float32),\n",
    "                             torch.tensor(X_val_video, dtype=torch.float32),\n",
    "                             torch.tensor(y_val, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test_audio, dtype=torch.float32),\n",
    "                              torch.tensor(X_test_video, dtype=torch.float32),\n",
    "                              torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f44b7-f207-45c0-8561-f5cdec3e3149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: 41734, Val indices: 9465, Test indices: 9277\n",
      "JSON error at line 1919: Extra data: line 1 column 120 (char 119), line content: {\"key\": \"S_M_00051_G2_task1_4_S00004\", \"wav_path\": \"data/S_M_00051_G2_task1_4_S00004.wav\", \"label\": 1, \"Frenchay\": 114}4{\"key\": \"S_M_00020_G4_task1_5_S00007\", \"wav_path\": \"data/S_M_00020_G4_task1_5_S00007.wav\", \"label\": 1, \"Frenchay\": 92}, skipping.\n",
      "Loaded 60476 valid clips, skipped 6712 entries from data_copy.list.\n",
      "Loading training embeddings...\n",
      "Loaded 5000 embeddings so far.\n",
      "Loaded 10000 embeddings so far.\n",
      "Loaded 15000 embeddings so far.\n",
      "Loaded 20000 embeddings so far.\n"
     ]
    }
   ],
   "source": [
    "# no normalization \n",
    "# Load data list from JSON lines\n",
    "def load_data_list(file_path='data_copy.list'):\n",
    "    data_list = []\n",
    "    all_keys =[]\n",
    "    skipped = 0\n",
    "    loaded = 0\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                entry = json.loads(line.strip())\n",
    "                if 'key' not in entry or 'wav_path' not in entry or 'label' not in entry:\n",
    "                    print(f\"Key error at line {line_num}: Missing 'key', 'wav_path', or 'label', line content: {line.strip()}\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                key = entry['key']\n",
    "                wav_path = os.path.join('audio', os.path.basename(entry['wav_path']))\n",
    "                video_path = os.path.join('video', os.path.splitext(os.path.basename(entry['wav_path']))[0] + '.avi')\n",
    "                label = int(entry['label'])\n",
    "                if label not in [0, 1, 2, 3]:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                spec_path = os.path.join('spectrograms', f'spec_{key}.npy')\n",
    "                if not os.path.exists(wav_path) or not os.path.exists(video_path) or not os.path.exists(spec_path):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                data_list.append((wav_path, video_path, label, key))\n",
    "                loaded += 1\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON error at line {line_num}: {e}, line content: {line.strip()}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            except KeyError as e:\n",
    "                print(f\"Key error at line {line_num}: Missing {e}, line content: {line.strip()}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            all_keys.append(key)\n",
    "    print(f\"Loaded {loaded} valid clips, skipped {skipped} entries from {file_path}.\")\n",
    "    return data_list, all_keys\n",
    "'''\n",
    "# Normalize embeddings (L2)\n",
    "def l2_normalize(X):\n",
    "    return X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "'''\n",
    "\n",
    "# Load saved audio/video embeddings\n",
    "\n",
    "def load_embeddings(indices, data_list, embeddings_dir='features_finetuned', batch_size=16):\n",
    "    X_audio, X_video, y = [], [], []\n",
    "    skipped = 0\n",
    "    loaded = 0\n",
    "    for i in indices:\n",
    "        if i >= len(data_list):\n",
    "            print(f\"Index {i} exceeds data_list length {len(data_list)}, skipping.\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "        try:\n",
    "            key = data_list[i][3]\n",
    "            label = data_list[i][2]\n",
    "            batch_num = i // batch_size\n",
    "            audio_embed_path = os.path.join(embeddings_dir, f'batch_{batch_num}', f'audio_embed_{key}.npy')\n",
    "            video_embed_path = os.path.join(embeddings_dir, f'batch_{batch_num}', f'video_embed_{key}.npy')\n",
    "            if not os.path.exists(audio_embed_path) or not os.path.exists(video_embed_path):\n",
    "                print(f\"Missing embedding for key {key}, skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            X_audio.append(np.load(audio_embed_path))\n",
    "            X_video.append(np.load(video_embed_path))\n",
    "            y.append(label)\n",
    "            loaded += 1\n",
    "            if loaded % 5000 == 0:\n",
    "                print(f\"Loaded {loaded} embeddings so far.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embedding for index {i}, key {data_list[i][3]}: {e}, skipping.\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "    print(f\"Loaded {loaded} embeddings, skipped {skipped} entries.\")\n",
    "    # Normalize before returning\n",
    "    #return l2_normalize(np.array(X_audio)), l2_normalize(np.array(X_video)), np.array(y)\n",
    "    return np.array(X_audio), np.array(X_video), np.array(y)\n",
    "\n",
    "# Load train/val/test indices\n",
    "try:\n",
    "    train_indices = np.load('train_indices.npy')\n",
    "    val_indices = np.load('val_indices.npy')\n",
    "    test_indices = np.load('test_indices.npy')\n",
    "    print(f\"Train indices: {len(train_indices)}, Val indices: {len(val_indices)}, Test indices: {len(test_indices)}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Ensure train_indices.npy, val_indices.npy, test_indices.npy exist.\")\n",
    "    raise\n",
    "\n",
    "# Load full data list\n",
    "data_list, all_keys = load_data_list('data_copy.list')\n",
    "\n",
    "# Sanity check on indices\n",
    "max_index = len(data_list) - 1\n",
    "if max(train_indices) > max_index or max(val_indices) > max_index or max(test_indices) > max_index:\n",
    "    print(f\"Error: Indices exceed data_list length ({max_index}). Re-run split_dataset.py with data_copy.list.\")\n",
    "    raise ValueError(\"Invalid indices.\")\n",
    "\n",
    "# Load embeddings into memory\n",
    "print(\"Loading training embeddings...\")\n",
    "X_train_audio, X_train_video, y_train = load_embeddings(train_indices, data_list, embeddings_dir='features_finetuned', batch_size=16)\n",
    "print(\"Loading validation embeddings...\")\n",
    "X_val_audio, X_val_video, y_val = load_embeddings(val_indices, data_list, embeddings_dir='features_finetuned', batch_size=16)\n",
    "print(\"Loading test embeddings...\")\n",
    "X_test_audio, X_test_video, y_test = load_embeddings(test_indices, data_list, embeddings_dir='features_finetuned', batch_size=16)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_audio, dtype=torch.float32),\n",
    "                               torch.tensor(X_train_video, dtype=torch.float32),\n",
    "                               torch.tensor(y_train, dtype=torch.long))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val_audio, dtype=torch.float32),\n",
    "                             torch.tensor(X_val_video, dtype=torch.float32),\n",
    "                             torch.tensor(y_val, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test_audio, dtype=torch.float32),\n",
    "                              torch.tensor(X_test_video, dtype=torch.float32),\n",
    "                              torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b61a5-72d8-4881-96c1-448baa5b4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract participant ID from the key\n",
    "def extract_participant_id(key):\n",
    "    # Split the key by underscores and take the first 3 components\n",
    "    # e.g., \"N_M_10010_G4_task3_4_04\" -> \"N_M_10010\"\n",
    "    parts = key.split('_')\n",
    "    if len(parts) < 3:\n",
    "        return None  # Invalid key format\n",
    "    if 'repeat' in parts:\n",
    "      participant_id = parts[1] + '_' + parts[2] + '_' + parts[3]\n",
    "    else:\n",
    "      participant_id = parts[0] + '_' + parts[1] + '_' + parts[2]\n",
    "    return participant_id\n",
    "\n",
    "# Function to extract participant characteristics\n",
    "def get_participant_info(participant_id):\n",
    "    parts = participant_id.split('_')\n",
    "    if len(parts) != 3:\n",
    "        return None, None\n",
    "    health_status = 'Healthy' if parts[0] == 'N' else 'Patient'\n",
    "    gender = 'Male' if parts[1] == 'M' else 'Female'\n",
    "    return health_status, gender\n",
    "\n",
    "\n",
    "# Calculate distribution, store labels, participant ID, health_status and gender\n",
    "def calculate_participant_distribution(keys):\n",
    "    # Dictionary to store counts of clips per participant\n",
    "    participant_counts = defaultdict(int)\n",
    "    # Dictionaries to store counts by health status and gender\n",
    "    health_gender_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # list to store the participant ID\n",
    "    participant_id_list = []\n",
    "    # list to store the health status and genders\n",
    "    health_gender_list = []\n",
    "\n",
    "\n",
    "    # Group by participant\n",
    "    for key in keys:\n",
    "        participant_id = extract_participant_id(key)\n",
    "        if participant_id is None:\n",
    "            continue\n",
    "        participant_id_list.append(participant_id)  #store the participant ID\n",
    "        # Increment count for this participant\n",
    "        participant_counts[participant_id] += 1\n",
    "\n",
    "        # Get health status and gender\n",
    "        health_status, gender = get_participant_info(participant_id)\n",
    "        if health_status and gender:\n",
    "            health_gender_counts[health_status][gender] += 1\n",
    "        health_gender_list.append(health_status+gender)\n",
    "\n",
    "    # Convert to lists for analysis\n",
    "    participants = list(participant_counts.keys())\n",
    "    counts = list(participant_counts.values())\n",
    "\n",
    "    return participants, counts, health_gender_counts, participant_id_list, health_gender_list\n",
    "\n",
    "# Calculate\n",
    "participants, counts, health_gender_counts, participant_id_list, health_gender_list= calculate_participant_distribution(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a975ff2-4540-44b7-808c-168603b730d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_embedding_scale(X_audio, X_video):\n",
    "    \"\"\"\n",
    "    Prints basic scale statistics for audio and video embeddings.\n",
    "    \n",
    "    Args:\n",
    "        X_audio (np.ndarray): Audio embeddings, shape [N, D]\n",
    "        X_video (np.ndarray): Video embeddings, shape [N, D]\n",
    "    \"\"\"\n",
    "    def print_stats(name, X):\n",
    "        print(f\"\\n{name} Embeddings:\")\n",
    "        print(f\"  Shape: {X.shape}\")\n",
    "        print(f\"  Min: {np.min(X):.4f}\")\n",
    "        print(f\"  Max: {np.max(X):.4f}\")\n",
    "        print(f\"  Mean: {np.mean(X):.4f}\")\n",
    "        print(f\"  Std: {np.std(X):.4f}\")\n",
    "\n",
    "    print_stats(\"Audio\", X_audio)\n",
    "    print_stats(\"Video\", X_video)\n",
    "check_embedding_scale(X_train_audio, X_train_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93df0ef7-1107-4e37-9d6c-b267caa8de32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Label Distribution:\n",
      "Label 0: 9044 clips (21.67%)\n",
      "Label 1: 19959 clips (47.82%)\n",
      "Label 2: 7405 clips (17.74%)\n",
      "Label 3: 5326 clips (12.76%)\n",
      "\n",
      "Validation Label Distribution:\n",
      "Label 0: 808 clips (8.54%)\n",
      "Label 1: 4580 clips (48.39%)\n",
      "Label 2: 2597 clips (27.44%)\n",
      "Label 3: 1480 clips (15.64%)\n",
      "\n",
      "Test Label Distribution:\n",
      "Label 0: 2058 clips (22.18%)\n",
      "Label 1: 4650 clips (50.12%)\n",
      "Label 2: 2423 clips (26.12%)\n",
      "Label 3: 146 clips (1.57%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze label distribution\n",
    "def print_label_distribution(y, set_name):\n",
    "    counter = Counter(y)\n",
    "    total = len(y)\n",
    "    print(f\"\\n{set_name} Label Distribution:\")\n",
    "    for label in range(4):\n",
    "        count = counter.get(label, 0)\n",
    "        percentage = (count / total * 100) if total > 0 else 0\n",
    "        print(f\"Label {label}: {count} clips ({percentage:.2f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "# Get labels from loaders\n",
    "def get_labels(loader):\n",
    "    labels = []\n",
    "    for _, _, lbls in loader:\n",
    "        labels.extend(lbls.numpy())\n",
    "    return np.array(labels)\n",
    "\n",
    "print_label_distribution(get_labels(train_loader), \"Training\")\n",
    "print_label_distribution(get_labels(val_loader), \"Validation\")\n",
    "print_label_distribution(get_labels(test_loader), \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c1945-52c8-49cc-97bf-374f10250ed5",
   "metadata": {},
   "source": [
    "# trianing "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c709386d-0335-42e2-8579-58f0da344736",
   "metadata": {},
   "source": [
    "linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3191f50-4a0f-44ea-b248-07456c345a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFusionClassifier(nn.Module):\n",
    "    def __init__(self, audio_dim=512, video_dim=512, proj_dim=128, num_classes=4):\n",
    "        super(LinearFusionClassifier, self).__init__()\n",
    "\n",
    "        # Separate projection layers\n",
    "        self.audio_proj = nn.Linear(audio_dim, proj_dim)\n",
    "        self.video_proj = nn.Linear(video_dim, proj_dim)\n",
    "\n",
    "        # Linear classifier on concatenated projections\n",
    "        self.classifier = nn.Linear(2 * proj_dim, num_classes)\n",
    "\n",
    "    def forward(self, audio_embeds, video_embeds):\n",
    "        a = self.audio_proj(audio_embeds)  # (B, 128)\n",
    "        v = self.video_proj(video_embeds)  # (B, 128)\n",
    "        x = torch.cat([a, v], dim=1)       # (B, 256)\n",
    "        return self.classifier(x)          # (B, num_classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b922d3a4-3509-4cb4-b037-5ff557492949",
   "metadata": {},
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9162029-5e2f-40d2-af5f-5d09988490d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp -- combined -128\n",
    "class MLPFusionClassifier(nn.Module):\n",
    "    def __init__(self, audio_dim=512, video_dim=512, hidden_dim=128, num_classes=4, dropout_rate=0.3):\n",
    "        super(MLPFusionClassifier, self).__init__()\n",
    "\n",
    "        # Project both modalities to hidden_dim\n",
    "        self.audio_proj = nn.Linear(audio_dim, hidden_dim)\n",
    "        self.video_proj = nn.Linear(video_dim, hidden_dim)\n",
    "\n",
    "        # Classifier on [audio_128 | video_128] = (B, 256)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(2 * hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(2 * hidden_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_embeds, video_embeds):\n",
    "        a = self.audio_proj(audio_embeds)  # (B, 128)\n",
    "        v = self.video_proj(video_embeds)  # (B, 128)\n",
    "        x = torch.cat([a, v], dim=1)       # (B, 256)\n",
    "        return self.classifier(x)          # (B, num_classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b672f7c6-f379-4a56-8cfc-d9ff8c26b8a8",
   "metadata": {},
   "source": [
    "crossattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "690bf3b7-140d-45ce-bc0e-4d8989855897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-attention classifier --512 -- audio query\n",
    "class CrossAttentionClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim=512, num_classes=4, dropout_rate=0.5):\n",
    "        super(CrossAttentionClassifier, self).__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=1, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_embeds, video_embeds):\n",
    "        audio_q = audio_embeds.unsqueeze(1)  # (B, 1, 512)\n",
    "        video_kv = video_embeds.unsqueeze(1)  # (B, 1, 512)\n",
    "        attn_output, _ = self.attn(query=audio_q, key=video_kv, value=video_kv)\n",
    "        output = self.classifier(attn_output.squeeze(1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e538cd-6413-4c6a-ad1c-6101eec48b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-attention classifier --128 --audio query\n",
    "class CrossAttentionClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim=512, hidden_dim=128, num_classes=4, dropout_rate=0.3):\n",
    "        super(CrossAttentionClassifier, self).__init__()\n",
    "        self.audio_proj = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.video_proj = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=1, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_embeds, video_embeds):\n",
    "        # Project both audio and video to hidden_dim\n",
    "        audio_q = self.audio_proj(audio_embeds).unsqueeze(1)  # (B, 1, hidden_dim)\n",
    "        video_kv = self.video_proj(video_embeds).unsqueeze(1)  # (B, 1, hidden_dim)\n",
    "        attn_output, _ = self.attn(query=audio_q, key=video_kv, value=video_kv)\n",
    "        output = self.classifier(attn_output.squeeze(1))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75db188a-6dc4-4873-8bc5-dafa49f55af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-attention classifier --128 --video query\n",
    "class CrossAttentionClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim=512, hidden_dim=128, num_classes=4, dropout_rate=0.3):\n",
    "        super(CrossAttentionClassifier, self).__init__()\n",
    "        self.audio_proj = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.video_proj = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=1, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_embeds, video_embeds):\n",
    "        # Project both audio and video to hidden_dim\n",
    "        audio_kv = self.audio_proj(audio_embeds).unsqueeze(1)  # (B, 1, hidden_dim)\n",
    "        video_q = self.video_proj(video_embeds).unsqueeze(1)  # (B, 1, hidden_dim)\n",
    "        attn_output, _ = self.attn(query=video_q, key=audio_kv, value=audio_kv)\n",
    "        output = self.classifier(attn_output.squeeze(1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f68c1e0-cca3-4373-bd23-43d739c31543",
   "metadata": {},
   "source": [
    "# self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7df323-031b-4492-9abd-d4c56d53714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define self-attention classifier\n",
    "class SelfAttentionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=512, proj_dim=128, num_classes=4):\n",
    "        super().__init__()\n",
    "        # Projection layers\n",
    "        self.audio_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, proj_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.video_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, proj_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        # Self-attention parameters (operate on 256-D after concatenation)\n",
    "        self.query = nn.Linear(proj_dim * 2, proj_dim * 2)\n",
    "        self.key = nn.Linear(proj_dim * 2, proj_dim * 2)\n",
    "        self.value = nn.Linear(proj_dim * 2, proj_dim * 2)\n",
    "        self.scale = torch.sqrt(torch.tensor(proj_dim * 2, dtype=torch.float32))\n",
    "        self.attn_dropout = nn.Dropout(0.5)\n",
    "        # Classification head\n",
    "        self.fc = nn.Linear(proj_dim * 2, num_classes)\n",
    "    \n",
    "    def forward(self, audio, video):\n",
    "        # Project to 128-D\n",
    "        audio = self.audio_proj(audio)  # (batch, 128)\n",
    "        video = self.video_proj(video)  # (batch, 128)\n",
    "        # Concatenate\n",
    "        x = torch.cat([audio, video], dim=1)  # (batch, 256)\n",
    "        # Single-head self-attention\n",
    "        q = self.query(x).unsqueeze(1)  # (batch, 1, 256)\n",
    "        k = self.key(x).unsqueeze(1)    # (batch, 1, 256)\n",
    "        v = self.value(x).unsqueeze(1)  # (batch, 1, 256)\n",
    "        attn_scores = torch.bmm(q, k.transpose(1, 2)) / self.scale  # (batch, 1, 1)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.attn_dropout(attn_weights)\n",
    "        attn_output = torch.bmm(attn_weights, v).squeeze(1)  # (batch, 256)\n",
    "        # Classification\n",
    "        logits = self.fc(attn_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40abb707-4810-4165-96aa-e220038563e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-head attention\n",
    "class MultiHeadFusionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=512, proj_dim=128, num_heads=4, num_classes=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Project both modalities to a shared space\n",
    "        self.audio_proj = nn.Linear(input_dim, proj_dim)\n",
    "        self.video_proj = nn.Linear(input_dim, proj_dim)\n",
    "\n",
    "        # Multihead self-attention over [audio, video]\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=proj_dim, num_heads=num_heads, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(proj_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(proj_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_embed, video_embed):\n",
    "        # Project audio/video to same space\n",
    "        a = self.audio_proj(audio_embed)  # (B, D)\n",
    "        v = self.video_proj(video_embed)  # (B, D)\n",
    "\n",
    "        # Stack into sequence: (B, 2, D)\n",
    "        x = torch.stack([a, v], dim=1)\n",
    "\n",
    "        # Self-attention over modalities\n",
    "        attn_out, _ = self.attn(x, x, x)  # (B, 2, D)\n",
    "\n",
    "        # Pool: mean or max over modalities\n",
    "        fused = attn_out.mean(dim=1)  # (B, D)\n",
    "\n",
    "        # Classification\n",
    "        return self.classifier(fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a80e7e13-dbee-4497-a553-76bf38afdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for one epoch\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for audio, video, labels in train_loader:\n",
    "        audio, video, labels = audio.to(device), video.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio, video)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * audio.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "    train_loss /= train_total\n",
    "    train_acc = train_correct / train_total * 100\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for audio, video, labels in val_loader:\n",
    "            audio, video, labels = audio.to(device), video.to(device), labels.to(device)\n",
    "            outputs = model(audio, video)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * audio.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total * 100\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Testing function with classification report\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for audio, video, labels in test_loader:\n",
    "            audio, video, labels = audio.to(device), video.to(device), labels.to(device)\n",
    "            outputs = model(audio, video)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * audio.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    test_loss /= test_total\n",
    "    test_acc = test_correct / test_total * 100\n",
    "    \n",
    "    # Generate classification report\n",
    "    print(\"\\nTest Set Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=[f\"Class {i}\" for i in range(4)], digits=4))\n",
    "    \n",
    "    return test_loss, test_acc, all_labels, all_preds\n",
    "\n",
    "# Training loop function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=30, best_model_path='classifier.pth'):\n",
    "    best_val_acc = 0.0\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Saved best model with Val Acc: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return train_losses, train_accs, val_losses, val_accs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a9bcec-dc02-4692-8588-10a616edb4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/30, Train Loss: 0.0507, Train Acc: 99.39%, Val Loss: 3.2979, Val Acc: 39.83%\n",
      "Saved best model with Val Acc: 39.83%\n",
      "Epoch 2/30, Train Loss: 0.0005, Train Acc: 100.00%, Val Loss: 3.9531, Val Acc: 39.63%\n",
      "Epoch 3/30, Train Loss: 0.0002, Train Acc: 100.00%, Val Loss: 4.2799, Val Acc: 40.27%\n",
      "Saved best model with Val Acc: 40.27%\n",
      "Epoch 4/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.3627, Val Acc: 40.20%\n",
      "Epoch 5/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.5554, Val Acc: 40.54%\n",
      "Saved best model with Val Acc: 40.54%\n",
      "Epoch 6/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.5382, Val Acc: 40.90%\n",
      "Saved best model with Val Acc: 40.90%\n",
      "Epoch 7/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.8251, Val Acc: 41.09%\n",
      "Saved best model with Val Acc: 41.09%\n",
      "Epoch 8/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.6051, Val Acc: 40.93%\n",
      "Epoch 9/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.6855, Val Acc: 39.81%\n",
      "Epoch 10/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.4840, Val Acc: 40.04%\n",
      "Epoch 11/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.1121, Val Acc: 39.65%\n",
      "Epoch 12/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0825, Val Acc: 41.27%\n",
      "Saved best model with Val Acc: 41.27%\n",
      "Epoch 13/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.8811, Val Acc: 39.04%\n",
      "Epoch 14/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.9217, Val Acc: 40.01%\n",
      "Epoch 15/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.1043, Val Acc: 40.34%\n",
      "Epoch 16/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.8777, Val Acc: 40.32%\n",
      "Epoch 17/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0118, Val Acc: 40.91%\n",
      "Epoch 18/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.2094, Val Acc: 40.37%\n",
      "Epoch 19/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.9903, Val Acc: 40.63%\n",
      "Epoch 20/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0939, Val Acc: 40.37%\n",
      "Epoch 21/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0123, Val Acc: 40.62%\n",
      "Epoch 22/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0008, Val Acc: 40.52%\n",
      "Epoch 23/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0296, Val Acc: 40.48%\n",
      "Epoch 24/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0117, Val Acc: 40.41%\n",
      "Epoch 25/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.9608, Val Acc: 40.57%\n",
      "Epoch 26/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.9966, Val Acc: 40.56%\n",
      "Epoch 27/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0314, Val Acc: 40.49%\n",
      "Epoch 28/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0508, Val Acc: 40.50%\n",
      "Epoch 29/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.9926, Val Acc: 40.52%\n",
      "Epoch 30/30, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 5.0298, Val Acc: 40.55%\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0     0.6937    0.9198    0.7909      2058\n",
      "     Class 1     0.6131    0.7069    0.6567      4650\n",
      "     Class 2     0.5348    0.1523    0.2371      2423\n",
      "     Class 3     0.2334    0.7945    0.3608       146\n",
      "\n",
      "    accuracy                         0.6106      9277\n",
      "   macro avg     0.5187    0.6434    0.5114      9277\n",
      "weighted avg     0.6046    0.6106    0.5722      9277\n",
      "\n",
      "\n",
      "Test Loss: 3.5228, Test Acc: 61.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training metrics plot as 'training_metrics.png'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Compute weights inversely proportional to class frequency\n",
    "def get_class_weights(y, num_classes=4):\n",
    "\n",
    "    counts = Counter(y)\n",
    "    total = sum(counts.values())\n",
    "    weights = [total / counts.get(i, 1) for i in range(num_classes)]\n",
    "    weights = torch.tensor(weights, dtype=torch.float32)\n",
    "    return weights / weights.sum()\n",
    "# Usage\n",
    "class_weights = get_class_weights(y_train, num_classes=4).to(device)\n",
    "# Initialize model, loss, and optimizer\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#model = SelfAttentionClassifier().to(device)\n",
    "#model = CrossAttentionClassifier().to(device)\n",
    "model = MLPFusionClassifier().to(device)\n",
    "#model = MultiHeadFusionClassifier().to(device)\n",
    "#model = LinearFusionClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)  #  class weights (imbalanced)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3\n",
    ")\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "train_losses, train_accs, val_losses, val_accs = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=30)\n",
    "\n",
    "# Load best model and test\n",
    "model.load_state_dict(torch.load('classifier.pth'))\n",
    "test_loss, test_acc, all_labels, all_preds = test_model(model, test_loader, criterion, device)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "# Plot training and validation metrics\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_accs) + 1), train_accs, label='Train Accuracy')\n",
    "plt.plot(range(1, len(val_accs) + 1), val_accs, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_metrics.png')\n",
    "plt.show()\n",
    "print(\"Saved training metrics plot as 'training_metrics.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f875e21-668e-4f42-ae91-866571429b78",
   "metadata": {},
   "source": [
    "# ~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a2b164e-299e-440a-9c99-088776baac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_participants = np.array(participant_id_list)[test_indices] #get the participant info for all test clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fc29367-5da5-4689-9e48-d8933dac0585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Segment): 0.5114\n",
      "F1 Score (Individual): 0.5208\n",
      "Final Evaluation Score: 5.7197\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79      2058\n",
      "           1       0.61      0.71      0.66      4650\n",
      "           2       0.53      0.15      0.24      2423\n",
      "           3       0.23      0.79      0.36       146\n",
      "\n",
      "    accuracy                           0.61      9277\n",
      "   macro avg       0.52      0.64      0.51      9277\n",
      "weighted avg       0.60      0.61      0.57      9277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_score(test_preds,test_labels,test_participant_list=test_participants):\n",
    "\n",
    "    # Compute F1-score for all segments (standard classification F1-score)\n",
    "    F1_segment = f1_score(test_labels, test_preds, average='macro')\n",
    "    print(f\"F1 Score (Segment): {F1_segment:.4f}\")\n",
    "\n",
    "    \n",
    "    #Compute individual f1 score \n",
    "    # Convert lists to NumPy arrays for easier manipulation\n",
    "    all_preds = np.array(test_preds)\n",
    "    all_labels = np.array(test_labels)\n",
    "\n",
    "    test_participant_np = np.array(test_participant_list)\n",
    "    \n",
    "    # Get unique participants\n",
    "    unique_test_participant = np.unique(test_participant_np)\n",
    "    \n",
    "    f1_individual_scores = []\n",
    "    \n",
    "    # Compute F1-score for each participant\n",
    "    for participant in unique_test_participant:\n",
    "        indices = np.where(test_participant_np == participant)[0]  # Ensure valid indices\n",
    "        if len(indices) == 0:  # Skip if no samples found\n",
    "            continue  \n",
    "\n",
    "        participant_preds = all_preds[indices]\n",
    "        participant_labels = all_labels[indices]\n",
    "    \n",
    "        f1_individual = f1_score(participant_labels, participant_preds, average='macro')\n",
    "        f1_individual_scores.append(f1_individual)\n",
    "    \n",
    "    # Compute overall F1-score for individuals\n",
    "    F1_individual = np.mean(f1_individual_scores)\n",
    "    print(f\"F1 Score (Individual): {F1_individual:.4f}\")\n",
    "\n",
    "\n",
    "    # Final Ranking Score\n",
    "    final_score = (F1_individual * 10) + F1_segment\n",
    "    print(f\"Final Evaluation Score: {final_score:.4f}\")\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_labels, test_preds))\n",
    "compute_score(all_preds,all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b68278-2a81-411e-8392-177c665dcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_clipwise_errors(test_preds, test_labels, test_participant_list, test_indices):\n",
    "    # Convert everything to NumPy arrays\n",
    "    preds = np.array(test_preds)\n",
    "    labels = np.array(test_labels)\n",
    "    participants = np.array(test_participant_list)\n",
    "    indices = np.array(test_indices)\n",
    "\n",
    "    # Build DataFrame to track each prediction\n",
    "    df = pd.DataFrame({\n",
    "        'dataset_index': indices,\n",
    "        'participant': participants,\n",
    "        'true_label': labels,\n",
    "        'predicted_label': preds,\n",
    "    })\n",
    "\n",
    "    # Mark whether each prediction is correct\n",
    "    df['correct'] = df['true_label'] == df['predicted_label']\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nCorrect predictions: {df['correct'].sum()} / {len(df)}\")\n",
    "    print(f\"Incorrect predictions: {len(df) - df['correct'].sum()}\")\n",
    "\n",
    "    # Optional: Confusion counts\n",
    "    print(\"\\nTop mistakes (True → Predicted):\")\n",
    "    confusion_counts = df[~df['correct']].groupby(['true_label', 'predicted_label']).size().sort_values(ascending=False)\n",
    "    print(confusion_counts.head(10))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e12fd3-1540-4353-9365-0f9462a5f361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
